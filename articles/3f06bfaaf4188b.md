---
title: "教師あり機械学習の基本"
emoji: "📘"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [機械学習]
published: false
---
# 教師あり機械学習の基本

機械学習はいろいろな場面で役立つ仕組みを紡ぎ出せます。その中で、実用的な成果を得られる教師あり学習のしくみを見ていきましょう。

---

## 目的は何の法則か

例えば、「今日は猫が顔を洗うか」を予想したい、と考えます。そうした場合、法則にしたいので、これまで、猫が顔を洗ったかを観察日記を付けていたら可能です。何もないところからは分析できません。実績になるデータが必要です。「朝顔がいつ咲くか」の予想をしたいなら、それも観察日記を付けて、多くの個体の観察日記があったら、分析することが可能です。こうしたものは気候の変動といつその事象が起こったかが記録されていればできそうです。カメラでずっと撮っておいて気象データを合わせてデータ化したら出来るかもしれません（出来ないかもしれません）。何にせよ、目的が明確になってることは必要です。それが監修しながら法則を導く学習をする、教師あり学習です。

---

## 教師あり機械学習の基本工程としくみ

教師あり学習とは、用意されたデータを観察して、答え合わせをすることで法則を見出す、自分用法則発見器を作ります。基本的な手順は以下になります。

 1. データの準備：学習する元を用意
 2. データの学習：学習し、学習モデルを作る
 3. 検証：学習モデルの性能を検証

人間が代わりにやっても出来ますが、かなり面倒なので機械にやらせます。

### 学習の単純な例
![](/images/Train.png)
電車が線路を走っているとします。測りだした場所から何メートルす進んだかを時刻と距離で表にします。

| 時刻 | 進んだ距離(m)  |
| ---- | ----:|
| 10:10 | 0m |
| 10:20 | 13m |
| 10:50 | 39m |
| 11:30 | 52m |

このとき、12:00には何メートル、進んでいるでしょうか。この命題を機械学習でやる場合、

- 目的変数（目的の値）：進んだ距離
- 説明変数（算出でヒントになる変数）：時刻

として、学習させると、例えば時刻を変数x、目的変数をyとしたら、

$$
y=f(x)
$$
として、数式を作り出します。そうしたら、12：00を与えたら、答えが出ます。
この数式の関数がどの様になっているかは、明確にできるものとむずかしいものがあります。また、**出てくる答えは必ず正確ではなく、確率的に高い値になる**ことに注意しましょう。

### 1.データの準備
先ず、学習するためのデータを用意します。数値化されていないものは数値にして、解析させます。
前期の例では時刻になっていますが、こうした場合は相対的な時刻にすることが多いです。他、様々なデータは数値化できれば何でも可能です。つまり、パソコンで観たり聴いたりしているなにかは全て、数値化されているので、可能です。これを、表の形にします。
説明変数をx~1~〜x~10~、目的変数をyとした場合、以下のようになります。
先程の電車の場合、距離に他の要因が影響しそうなら、それらを加えます。

| x~1~ | x~2~ | x~3~ | x~4~ | ... | x~10~ | y |
| -- | -- | -- | -- | -- | -- | -- | 
|  |  | | | | | | | | | | | | 
| 20 | | | | | | 13 |
| 50 | | | | | | 39 |
| 30 | | | | | | 52 |
|  |  | | | | | | | | | | | | 
|  |  | | | | | | | | | | | | 
|  |  | | | | | | | | | | | | 


これをプログラミングでやる場合、CSVで読み込んだりデータベースのAPIを呼び出すなどするでしょう。

### 学習させる

用意したデータを指定したモデルに学習させます。モデルにはいろいろな種類があり、また、それに合わせてデータの加工も必要です。基本的に数値化するのは必然ですが、どのような数値にするかは場合によります。前記の電車の場合は、単純にどれでも適合できそうです。

#### データの分割

データは一部を学習のテスト用に、一部を検証用に用います。学習は答え合わせをしながら目的変数を導く仕組みを構築し学習モデルが成果物として書き出されます。

![](/images/Gemini_Generated_Image_hsj0gmhsj0gmhsj0.png)

例えばデータが100行あった場合、全体の80行を学習用にして、その行での説明変数から目的変数を導くように訓練します。訓練したモデルを使って、残りの20行で答え合わせをして、できるだけ答えが合うよう、学習を繰り返します。

#### データ分割の種類と役割

| データの種類 | 割合の目安 | 役割 | 使用タイミング |
| ---- | :----: | ---- | ---- |
| 訓練データ（Train） | 60-80% | モデルにパターンを学習させる。このデータで答え合わせをしながらモデルを構築 | 学習時 |
| 検証データ（Validation） | 10-20% | モデルの性能を評価し、パラメータ調整に使用。過学習を防ぐ | 学習時・調整時 |
| テストデータ（Test） | 10-20% | 最終的なモデルの性能を評価。学習に一切使わない未知のデータ | 最終評価時 |

**例：100行のデータを分割する場合**
- 訓練データ：60行（モデルを訓練）
- 検証データ：20行（パラメータ調整・過学習チェック）
- テストデータ：20行（最終性能評価）

どの行をどれに使うか、全体を使うかなどで成果は変わります、これを試しながら進めます。

#### モデルの選択
入力した説明変数を判断する機構のことを**学習モデル**と呼びます。教師あり学習にまつわる立場は以下の人がいます。

1. モデルを作る汎用的な元を学術的に開発しているひと：企業や学術機関などの研究開発部門
1. モデルの元を利用して自分用のモデルをつくるひと：利活用する組織の担当
1. 出来上がったモデルを利用するひと：組織の顧客、一般人

ここでKaggleのコンペに参加するための開発は、２つ目の自分用のモデルをつくるひとに該当します。そうした場合、モデルの元は何を使うか、選択が必要になります。また、自動で選んでくれる機構を用いることも可能です。


| モデル名 | どういう学習に向いているか |
| ---- | ---- |
| 線形回帰（Linear Regression） | 数値予測、説明変数と目的変数の関係が直線的な場合。データの傾向を単純な式で表現したいとき |
| ロジスティック回帰（Logistic Regression） | 二値分類（Yes/No、合格/不合格など）、データが2つのグループに分かれる場合の予測 |
| 決定木（Decision Tree） | 分類・回帰の両方、データの特徴を「もし〜ならば」のルールで分岐させて判断。解釈しやすい |
| ランダムフォレスト（Random Forest） | 分類・回帰の両方、複数の決定木を組み合わせて精度向上。過学習しにくく、安定した予測 |
| 勾配ブースティング（Gradient Boosting / LightGBM / XGBoost） | 分類・回帰の両方、Kaggleなどのコンペで高精度を目指す場合。テーブルデータで特に強力 |
| ニューラルネットワーク（Neural Network / DNN） | 分類・回帰の両方、画像・音声・テキストなど複雑なパターン認識。大量データで威力を発揮 |

とりあえずどれを選んだら良いか分からない場合、似たデータを解析しているモデルを参考にして仮で組むのが得策です。Kaggleでよく見かけるは、LightGBM,XGBoost,ニューラルネットワーク系ですね。

### 検証する
プログラム的に問題がなければ、時間の長短はありますが（数秒から数日）、何らかのモデルが出来上がります。出来上がるモデルは、ターゲットの変数や分類などを確率的に高い予想をたてるだけで、絶対にこれだというものになっているかは分かりません。ニュートンの力学のようにはいかないものが常です。誤差がほぼない場合、既存の統計から導く確率でも出せそうな命題かも知れませんね。

---

## 改善を試みる方法

出来上がったモデルで満足するかを観て、納得できなければ改善を進めます。出来上がるものは確率的な答えだけなので完璧になることはありません。また、訓練が完璧な場合のほうが、適切ではないモデルが出来上がっている場合があります。

#### 過学習に注意
元の問題に合わせすぎると、想定したものと違うモデルになる場合があります。

##### 難しい数式にすると何でもフィットしやすくなる

訓練データ：
1 → 2, 2 → 4, 3 → 6, 4 → 8, 5 → 10
これは真の関係が y = 2x（比例）である典型的な例です。

正しい（単純な）モデル：
線形（一次）モデル y = 2x を学べば、未知の x=6 に対して y=12 を正しく予測できます。

過学習の誘導：
訓練点をすべて「ぴったり通る」ように高次の多項式（例：4次多項式）で近似すると、訓練データ上は誤差がほぼ0になるが、訓練に無い入力（x=6 など）での予測が真の関係から大きく外れることがあります（＝一般化できない）。何等か、むずかしいことをやり過ぎて、以下のような数式に至っても、元のデータには合います。

$$
y = -0.03476x^4 + 0.21444x^3 + 0.00863x^2 + 0.61344x + 1.49628
$$

![](/images/cacd5505-a6f9-49a0-96e6-55a633f5ad7f.jpg)

データには色々なノイズが入っていたり、何かの影響で突然、へんな値になっている場合もあります。そうした、平均値や最頻値から離れた値（外れ値）まで合わせてしまうとこうしたことがより起こりえます。そこも面倒を見る関数を作り出せば、他のハズレ値に合わないばかりか、平常と捉えられる値にも合わなくなる可能性があります。訓練データに適合しすぎることを防ぐ必要があります。

### データの精査
もっと良いモデルにしたい場合、用意したデータによって改善することがあります。色々なパターンがあるので一様に全てを試すのは資源的に難しいことが多く、統計的に推論して考察することが必要です。

#### ラベルを考える
説明変数による表の列で、どのような構成が効果的かを探ります。

##### 相関関係を分析する
目的変数との関係が見られるものを揃えるのは、常套手段です。直線グラフになるような相関関係は分かりやすいでしょう。分布の比較に箱ひげを使うてもあります。
以下に一部を挙げます。
| 手法 | 主な出力 | 用途 |
|------|-----------|------|
| 散布図 | 点の分布 | 視覚的な傾向確認 |
| 相関ヒートマップ | 相関係数行列 | 線形関係の強さ |
| 箱ひげ図 | 分布の形 | カテゴリ別のばらつき比較 |
| クロス集計 | 比率表 | カテゴリ間の関係性 |
| 回帰分析 | 係数・p値 | 影響度と有意性の定量評価 |

散布図
![散布図](/images/scatter_plot.png)

ヒートマップ
![ヒートマップ](/images/correlation_heatmap.png)

箱ひげ図
![箱ひげ図](/images/box_plot.png)

個々の部分のヒントは統計学になります。ヒントをLLMに尋ねるのもいいと思います。

##### 数値が相応しい形式か
例えば与える数値が日付の場合、曜日に変換したらグラフでで傾向が見られた、という場合なら、曜日を項目として設けた方が良い結果に繋がる可能性があります。また、極端に大きい値や小さい値は正規化した方が良い場合があります。正規化にはいくつか方法がありますが、外れ値に注意した変換が必要です。
全てを数値化して演算するニューラルネットなどのモデルは正規化が効きます。

##### 多ければ良いと限らない不思議
これはKaggleなどで実際にやってるとあるのですが、説明変数が多いことが効果的とは限らない、ということです。LGBMで何等か追加してパラメータも変えても良い結果にならない場合があります。
![](/images/Gemini_Generated_Image_9gxa059gxa059gxa.png)
こうなる理由はいくつか考えられます。
なるほど。つまり **「説明変数を増やしても必ずしもモデル精度が向上しない」現象** について、LightGBM などの勾配ブースティング系で見られるケースです。

###### 1. ノイズや相関の影響

###### (1) ノイズ変数の追加

  例えば、「猫が顔を洗う」データを取るときに、そのときサイコロを横で振って出目を記録したとします。絶対とは言えないですが、ほぼ関係なさそうです。でも関係あるかもしれないのでデータに入れたとすると、その数値に引っ張られて変な結果を招く可能性が高いのが、想像できると思います。有効な情報を持たない変数（ランダムノイズや無関係な特徴量）を増やすと、モデルがそのノイズに引っ張られて学習してしまうことがあります。
  ブースティング系は強力に特徴量を活かせる分、ノイズにも敏感になりやすいです。

###### (2) 高い相関の説明変数

同じ情報を持つ特徴量を増やしても、新しい情報がほとんどないため、予測性能の改善には寄与しません。
過学習のリスクが増えるだけで、テスト精度は改善しないことが多いです。ただし、やってみないと分からないともいえるので、効果的ではなかった場合は、想定通り無駄だったという結論になりますが、そうすれば他のものを探す候補が減るので、予想したら試して実験することも大切です。

**高い相関の説明変数の具体例：**

| 目的変数 | 高相関な説明変数の例 | 問題点 |
| ---- | ---- | ---- |
| 住宅価格 | 延床面積 と 部屋数 | 延床面積が広ければ部屋数も多い傾向。ほぼ同じ情報を重複して持つ |
| 売上予測 | 広告費（円） と 広告費（ドル） | 為替レート固定なら完全に同じ情報。片方だけで十分 |
| 体重予測 | 身長（cm） と 身長（m） | 単位が違うだけで同一の情報。どちらか一方のみ使用すべき |
| 気温予測 | 摂氏温度 と 華氏温度 | 変換式で結びついており、独立した情報ではない |
| 試験の合格予測 | 模試A の点数 と 模試B の点数（同じ範囲） | 両方とも同じ学力を測定しており、相関が非常に高い |

これらの変数を両方入れても新しい情報は増えず、モデルが混乱したり過学習したりする原因になります。

###### 2. モデルのバイアスと容量の限界

情報を増やしたとき、必要に応じてパラメータを調整する必要があります。LightGBM は決定木ベースで特徴量の分割を行うため、**木の深さや葉の数**には情報を処理できる限界があります。
追加した特徴量を活かすためには、木の深さを増やす、葉数を増やすなど容量を増やす必要がありますが、そうすると過学習のリスクが高まります。
実務では、追加した変数に対してモデル容量を調整しても、**テストデータで精度が伸びない**ことがあります。

###### 3. 特徴量選択・重要度の問題

LightGBM は自動的に特徴量を選んで使います。
追加した特徴量が既存の特徴量より情報量が少ない場合、モデルはそもそも使わないことがあります。
そのため **変数を増やしても性能がほぼ変わらない**、あるいはわずかに悪化することがあります。

###### 4. データのサイズ・サンプル数の制約

* 説明変数が増えても、サンプル数が少ない場合は **次元の呪い** が発生します。
* 多くの変数を追加すると、モデルは訓練データに合わせすぎて、無用に複雑な構造になり過学習しやすく、テストデータで精度が伸びません。

###### 5. パラメータ調整の難しさ

* 追加変数に合わせて `num_leaves` や `max_depth`、`learning_rate` を変えても、最適値の探索空間が広くなるため、**局所最適に陥ること**があります。
* 特に Kaggle のようにデータが非公開の場合、公開スコアと非公開スコアの差が大きく出ることもあります。

*💡 まとめの推察*

1. 追加変数がノイズや相関の強い特徴量だと効果がない
2. モデル容量（木の深さや葉数）とのバランスが悪い
3. LightGBM は特徴量を自動選択するので、追加変数が活かされない場合がある
4. サンプル数が少ない場合は次元の呪いで精度が伸びない
5. パラメータ調整が複雑になり、改善が難しい

こうしたことに注意して追加しましょう。

##### 数値に置き換えるカテゴリとワンホット（LGBMなど）
文字列は基本的に受け入れられないので、何等か変える必要があります。例えばぬいぐるみの売上データで犬、猫、ひつじ、クマの種類を変数として学習をしたいとします。学習には数値化が必要なので、以下の数値を割り当てたとします。

| 動物 | 割り当てる数字 |
|:--:|--:|
| 犬 | 1 |
| 猫 | 2 |
| ひつじ | 3 |
| クマ | 4 |

データ上では番号を変数として扱うため、大きさを比較したり、「犬を２倍にしたら猫」などの謎の法則を見出してしまいます。こうしたことを避けたい場合は、ワンホットやカテゴリのラベルであると認識させる、などの方法があります。いろいろな方法があるので、調べて検討してください。

###### ワンホット化の例（ダミー変数）

| 動物 | 犬 | 猫 | ひつじ | クマ |
|:--:|:--:|:--:|:--:|:--:|
| 犬 | 1 | 0 | 0 | 0 |
| 猫 | 0 | 1 | 0 | 0 |
| ひつじ | 0 | 0 | 1 | 0 |
| クマ | 0 | 0 | 0 | 1 |

それぞれのカテゴリを 0/1 の列に展開することで、「大小関係」という誤った仮定を避けられます。

###### カテゴリ定義して LightGBM で学習する（Python）

カテゴリ列をそのまま使いたい場合は、pandas の `category` 型にして LightGBM に渡します。One-Hot せずに扱えるため、高次元化を防げます。

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from lightgbm import LGBMRegressor  # 分類なら LGBMClassifier

# サンプルデータ（target は目的変数の例）
df = pd.DataFrame({
  'animal': ['犬', '猫', 'ひつじ', 'クマ', '犬', '猫', 'クマ', 'ひつじ'],
  'feature1': [10, 12, 9, 20, 11, 13, 18, 8],
  'target': [100, 120, 95, 200, 110, 125, 190, 90]
})

# カテゴリ型に変換（ここがポイント）
df['animal'] = df['animal'].astype('category')

X = df[['animal', 'feature1']]
y = df['target']

X_train, X_valid, y_train, y_valid = train_test_split(
  X, y, test_size=0.25, random_state=42
)

# 回帰モデルの例（分類なら LGBMClassifier に置き換え）
model = LGBMRegressor(
  n_estimators=200,
  learning_rate=0.05,
  random_state=42
)

# pandas の category 型をそのまま渡す。必要に応じて categorical_feature を明示
model.fit(
  X_train, y_train,
  categorical_feature=['animal'],
  eval_set=[(X_valid, y_valid)],
  verbose=False
)

pred = model.predict(X_valid)
print(pred[:5])
```

ポイント：
- `df['animal'].astype('category')` にすることで、LightGBM がカテゴリ列として解釈します。
- One-Hot と比べて列爆発を避けられ、木ベースのモデルでは精度・速度の面で有利なことが多いです。

##### 欠損値、外れ値の扱い

データは、記録に残っていない部分があったり、なにかの観測や会計記録などによる値によって構成されます。その場合、微細な誤差を含んだり、何かの理由で離れた値を刻むことがあります。そうした部分を考慮してデータを構築する必要があります。

欠損値の対応には以下の例があります。
- とにかく消す
  - 行・列の削除：`dropna()`（`axis=0/1`、`subset`、`thresh` で条件指定）
- 何かで埋める
  - 単純代入（数値）：平均・中央値・最頻値・定数で埋める（`fillna()`）
  - 単純代入（カテゴリ）：最頻カテゴリ・「Unknown」などの擬似カテゴリで埋める
  - グループ別代入：`groupby()` 単位で平均・中央値を使って補完（例：店舗ごと、カテゴリごと）
  - 前方/後方補完：`ffill` / `bfill`（時系列や並びに意味がある場合）
  - 補間（interpolate）：`interpolate(method='time'|'linear'|'spline'...)`（時系列の連続量に有効）
- 欠損が在ることを学習の変数にする
  - 欠損フラグ列の追加：`isna().astype(int)` で欠損の有無を特徴量として持たせる
- 補間にアルゴリズムを用いる
  - モデルによる推定補完：`KNNImputer`、`IterativeImputer`（多変量補完）や回帰・分類モデルでの推定
  - 高欠損率列の削除：一定割合以上の欠損がある列をドロップ（情報量が乏しい場合）
  - 整合性ベースの対応：複数列の整合が崩れる行はまとめて削除 or ドメイン知識で補完ルール化


効果的なものを予測を立て、検証して利用しましょう。
他方、外れ値は、無用なデータを取り入れない工夫です。外れ値とする基準は、統計的に見て極端に大きかったり小さいデータを省き、欠損値のように代替する値で埋めるか、その行または列を取り去ることも有効です。
しかしながら、外れ値の判定はなかなか難しいです。
例えば、何かの売上予測で、突然、値が大きくなっている場合があるとします。それを省いたら良いかは単純には分かりません。何かに相関しているかもしれません。例えばお餅がお正月だけ売れる、等です。
また、単純な値としてみたら、外れの値と思うとそうでもない、という場合もあります。
この表は３のべき乗を並べました。

| k | 3のk乗 |
|:--:|----:|
| -5 | 0.004115 |
| -4 | 0.012346 |
| -3 | 0.037037 |
| -2 | 0.111111 |
| -1 | 0.333333 |
| 0  | 1 |
| 1  | 3 |
| 2  | 9 |
| 3  | 27 |
| 4  | 81 |
| 5  | 243 |

対数を取ると大きな値の差を圧縮でき、外れ値の見え方が変わることがあります。-5乗と+５乗では、出てきた小数をみるとかなり離れてますが、対数にしたらそうでもありません。こうした、指数・対数という数値の感覚は人間の知覚にも関係するので、よく扱う形です。例えば楽器の1オクターブの上下は、周波数の２倍・2分の1になっており、周波数の対数表現になります。音の大きさを表すデシベルも同様です。何かを観測するときに指数・対数が便利な場合は、対数による単位を使っています。

##### 変数同士の組み合わせ・追加
何かと何かを掛け算したり引き算して絶対値をとるなどで演算し、新たな何かを生み出す方法です。学習するときに効き目のあるラベルであれば、既に意味がありますが、組み合わせたら新たな価値を生む可能性があります。何かの寸法で縦と横があったら、面積にしたら更に効果的になる可能性がある、などです。また、時系列データなら、他の行を使って前日との差を入れると変化があるかも知れません。学習する中身をあらかじめ人間がお膳立てする形ですね。 

- 面積（例：不動産・製造）: $\text{面積} = \text{縦} \times \text{横}$
  - 寸法の2変数から合成して、価格や重さなどの予測に効くことが多い
- 伸び率（例：売上の時系列）: $\text{伸び率} = \dfrac{\text{当日売上} - \text{前日売上}}{\text{前日売上}}$
  - 差よりも比率で変化を表すと、規模の違いを正規化できる
- 客単価（例：小売・飲食）: $\text{客単価} = \dfrac{\text{売上}}{\text{来店者数}}$
  - 総売上の大小に引っ張られず、純粋な“1人あたり”の指標として有効
- ラグ特徴量（例：時系列の基礎）:
  -  $y_{t-1},\; y_{t-7},$
  - $\; \text{移動平均} = \dfrac{1}{k}\sum_{i=1}^{k} y_{t-i},\;$
  - $ \text{差分} = y_t - y_{t-1}$
    - ラグ特徴量とは、時系列で過去の値（例：1日前・7日前など）を現在の説明変数として加える手法で、直近の動きや周期性を取り込むための基本的な特徴量です。
    - 直近期の影響や季節性を取り込み、ノイズを平滑化するのに有効（ただし未来情報の混入に注意が必要）

#### 学習データの分割を考える
学習する範囲を固定して開発すると、学習時のスコアと検証時に改善の違いが観られる場合、過学習の可能性があります。そうした場合、データ分割を見直すことも検討します。

##### 行の範囲を考える
過学習になる場合、学習データと検証データで違った偏りがあり、それに合わせて学習している可能性があります。また、時系列での場合は連続データが乏しいと有効に使えない場合があります。それらを意識して取り除いたり、変数化します。
- 特定の偏りを防ぐ
  - 未来情報の混入を防ぐ：予測基準時点より後の行や、未来を含む集計特徴量（例：月末合計）を学習に入れない（リーク対策）。
  - 季節性・イベントを揃える：学習と検証の両方に同じ季節/曜日構成/キャンペーン周期が含まれるように期間を選ぶ。
  - 異常期間の除外・フラグ化：障害、計測ミス、在庫切れ、価格改定直後、プロモーション集中期間などは除外するか、専用フラグ列で扱う。
  - エンティティの独立性を保つ：同一顧客・店舗・セッションの行が train/test を跨がないように Group 単位で分割（データリーク防止）。
  - 重複・高相関行の整理：同一レコードの重複や連続サンプリングでほぼ同一の行は間引いてバイアスを抑える。
  - 分層サンプリングを意識：期間/地域/カテゴリなどの比率が大きく偏らないように層別して抽出する。
  - サンプル重みで時系列を希釈：古い行に小さな重み、直近に大きな重みを付ける（完全に捨てずに影響度を調整）。
  - 時系列で過去に遡りすぎない：制度変更・ビジネス仕様変更・概念ドリフトで古い行が有害化することがあるため、直近Nヶ月/四半期などに絞る、またはスライディングウィンドウで更新。

- 特徴量が不十分になる可能性の回避
  - ラグ/移動統計の整合：ラグ・移動平均・移動分散を作る場合、学習に使う行の前方に十分な履歴がある期間だけを採用する。
  - コールドスタート評価：新規顧客/新商品など“未知エンティティ”は履歴特徴が乏しいため、検証側に回して性能確認し、必要に応じてベースライン特徴（カテゴリ・静的属性）やルールを併用。
  - スキーマ/計測変更境界で分ける：仕様変更で特徴量の定義が変わると学習・推論の不整合が生じるため、境界でモデルを分けるか変換を統一する。

##### 交差検証を検討する


### モデルの検討
#### モデルは選べる
##### 得意分野を考える
##### 自動で選んでもらう
#### パラメータのチューニング
##### 自分で試す方法
##### 自動でチューニング
#### 複数モデルの活かし方

---

## 上位勢を参考にする
### 参加目的を考えて利用を推奨
### LLMに細かく解説させる
### 環境が違うと再現できないので注意