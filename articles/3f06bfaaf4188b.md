---
title: "教師あり機械学習の基本"
emoji: "📘"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [機械学習]
published: false
---
# 教師あり機械学習の基本

機械学習はいろいろな場面で役立つ仕組みを紡ぎ出せます。その中で、実用的な成果を得られる教師あり学習のしくみを見ていきましょう。

---

## 目的は何の法則か

例えば、「今日は猫が顔を洗うか」を予想したい、と考えます。そうした場合、法則にしたいので、これまで、猫が顔を洗ったかを観察日記を付けていたら可能です。何もないところからは分析できません。実績になるデータが必要です。「朝顔がいつ咲くか」の予想をしたいなら、それも観察日記を付けて、多くの個体の観察日記があったら、分析することが可能です。こうしたものは気候の変動といつその事象が起こったかが記録されていればできそうです。カメラでずっと撮っておいて気象データを合わせてデータ化したら出来るかもしれません（出来ないかもしれません）。何にせよ、目的が明確になってることは必要です。それが監修しながら法則を導く学習をする、教師あり学習です。

---

## 教師あり機械学習の基本工程としくみ

教師あり学習とは、用意されたデータを観察して、答え合わせをすることで法則を見出す、自分用法則発見器を作ります。基本的な手順は以下になります。

 1. データの準備：学習する元を用意
 2. データの学習：学習し、学習モデルを作る
 3. 検証：学習モデルの性能を検証

人間が代わりにやっても出来ますが、かなり面倒なので機械にやらせます。

### 学習の単純な例
![](/images/Train.png)
電車が線路を走っているとします。測りだした場所から何メートルす進んだかを時刻と距離で表にします。

| 時刻 | 進んだ距離(m)  |
| ---- | ----:|
| 10:10 | 0m |
| 10:20 | 13m |
| 10:50 | 39m |
| 11:30 | 52m |

このとき、12:00には何メートル、進んでいるでしょうか。この命題を機械学習でやる場合、

- 目的変数（目的の値）：進んだ距離
- 説明変数（算出でヒントになる変数）：時刻

として、学習させると、例えば時刻を変数x、目的変数をyとしたら、

$$
y=f(x)
$$
として、数式を作り出します。そうしたら、12：00を与えたら、答えが出ます。
この数式の関数がどの様になっているかは、明確にできるものとむずかしいものがあります。また、**出てくる答えは必ず正確ではなく、確率的に高い値になる**ことに注意しましょう。

### 1.データの準備
先ず、学習するためのデータを用意します。数値化されていないものは数値にして、解析させます。
前期の例では時刻になっていますが、こうした場合は相対的な時刻にすることが多いです。他、様々なデータは数値化できれば何でも可能です。つまり、パソコンで観たり聴いたりしているなにかは全て、数値化されているので、可能です。これを、表の形にします。
説明変数をx~1~〜x~10~、目的変数をyとした場合、以下のようになります。
先程の電車の場合、距離に他の要因が影響しそうなら、それらを加えます。

| x~1~ | x~2~ | x~3~ | x~4~ | ... | x~10~ | y |
| -- | -- | -- | -- | -- | -- | -- | 
|  |  | | | | | | | | | | | | 
| 20 | | | | | | 13 |
| 50 | | | | | | 39 |
| 30 | | | | | | 52 |
|  |  | | | | | | | | | | | | 
|  |  | | | | | | | | | | | | 
|  |  | | | | | | | | | | | | 


これをプログラミングでやる場合、CSVで読み込んだりデータベースのAPIを呼び出すなどするでしょう。

### 学習させる

用意したデータを指定したモデルに学習させます。モデルにはいろいろな種類があり、また、それに合わせてデータの加工も必要です。基本的に数値化するのは必然ですが、どのような数値にするかは場合によります。前記の電車の場合は、単純にどれでも適合できそうです。

### データの分割

データは一部を学習のテスト用に、一部を検証用に用います。学習は答え合わせをしながら目的変数を導く仕組みを構築し学習モデルが成果物として書き出されます。

![](/images/Gemini_Generated_Image_hsj0gmhsj0gmhsj0.png)

例えばデータが100行あった場合、全体の80行を学習用にして、その行での説明変数から目的変数を導くように訓練します。訓練したモデルを使って、残りの20行で答え合わせをして、できるだけ答えが合うよう、学習を繰り返します。

#### データ分割の種類と役割

| データの種類 | 割合の目安 | 役割 | 使用タイミング |
| ---- | :----: | ---- | ---- |
| 訓練データ（Train） | 60-80% | モデルにパターンを学習させる。このデータで答え合わせをしながらモデルを構築 | 学習時 |
| 検証データ（Validation） | 10-20% | モデルの性能を評価し、パラメータ調整に使用。過学習を防ぐ | 学習時・調整時 |
| テストデータ（Test） | 10-20% | 最終的なモデルの性能を評価。学習に一切使わない未知のデータ | 最終評価時 |

**例：100行のデータを分割する場合**
- 訓練データ：60行（モデルを訓練）
- 検証データ：20行（パラメータ調整・過学習チェック）
- テストデータ：20行（最終性能評価）

どの行をどれに使うか、全体を使うかなどで成果は変わります、これを試しながら進めます。

#### 教師あり学習の代表的なモデル

| モデル名 | どういう学習に向いているか |
| ---- | ---- |
| 線形回帰（Linear Regression） | 数値予測、説明変数と目的変数の関係が直線的な場合。データの傾向を単純な式で表現したいとき |
| ロジスティック回帰（Logistic Regression） | 二値分類（Yes/No、合格/不合格など）、データが2つのグループに分かれる場合の予測 |
| 決定木（Decision Tree） | 分類・回帰の両方、データの特徴を「もし〜ならば」のルールで分岐させて判断。解釈しやすい |
| ランダムフォレスト（Random Forest） | 分類・回帰の両方、複数の決定木を組み合わせて精度向上。過学習しにくく、安定した予測 |
| 勾配ブースティング（Gradient Boosting / LightGBM / XGBoost） | 分類・回帰の両方、Kaggleなどのコンペで高精度を目指す場合。テーブルデータで特に強力 |
| ニューラルネットワーク（Neural Network / DNN） | 分類・回帰の両方、画像・音声・テキストなど複雑なパターン認識。大量データで威力を発揮 |

とりあえずどれを選んだら良いか分からない場合、似たデータを解析しているモデルをえらんで仮で組むのが得策です。

### 検証する
プログラム的に問題がなければ、時間の長短はありますが（数秒から数日）、何らかのモデルが出来上がります。出来上がるモデルは、ターゲットの変数や分類などを確率的に高い予想をたてるだけで、絶対にこれだというものになっているかは分かりません。ニュートンの力学のようにはいかないものが常です。誤差がほぼない場合、既存の統計から導く確率でも出せそうな命題かも知れませんね。

---

## 改善を試みる方法

出来上がったモデルで満足するかを観て、納得できなければ改善を進めます。出来上がるものは確率的な答えだけなので完璧になることはありません。また、訓練が完璧な場合のほうが、適切ではないモデルが出来上がっている場合があります。

#### 過学習に注意
元の問題に合わせすぎると、想定したものと違うモデルになる場合があります。

##### 難しい数式にすると何でもフィットしやすくなる

訓練データ：
1 → 2, 2 → 4, 3 → 6, 4 → 8, 5 → 10
これは真の関係が y = 2x（比例）である典型的な例です。

正しい（単純な）モデル：
線形（一次）モデル y = 2x を学べば、未知の x=6 に対して y=12 を正しく予測できます。

過学習の誘導：
訓練点をすべて「ぴったり通る」ように高次の多項式（例：4次多項式）で近似すると、訓練データ上は誤差がほぼ0になるが、訓練に無い入力（x=6 など）での予測が真の関係から大きく外れることがあります（＝一般化できない）。何等か、むずかしいことをやり過ぎて、以下のような数式に至っても、元のデータには合います。

$$
y = -0.03476x^4 + 0.21444x^3 + 0.00863x^2 + 0.61344x + 1.49628
$$

![](/images/cacd5505-a6f9-49a0-96e6-55a633f5ad7f.jpg)

データには色々なノイズが入っていたり、何かの影響で突然、へんな値になっている場合もあります。そうした、平均値や最頻値から離れた値（外れ値）まで合わせてしまうとこうしたことがより起こりえます。そこも面倒を見る関数を作り出せば、他のハズレ値に合わないばかりか、平常と捉えられる値にも合わなくなる可能性があります。訓練データに適合しすぎることを防ぐ必要があります。

### データの精査
もっと良いモデルにしたい場合、用意したデータによって改善することがあります。色々なパターンがあるので一様に全てを試すのは資源的に難しいことが多く、統計的に推論して考察することが必要です。

#### ラベルを考える
説明変数による表の列で、どのような構成が効果的かを探ります。

##### 相関関係を分析する
目的変数との関係が見られるものを揃えるのは、常套手段です。直線グラフになるような相関関係は分かりやすいでしょう。分布の比較に箱ひげを使うてもあります。
以下に一部を挙げます。
| 手法 | 主な出力 | 用途 |
|------|-----------|------|
| 散布図 | 点の分布 | 視覚的な傾向確認 |
| 相関ヒートマップ | 相関係数行列 | 線形関係の強さ |
| 箱ひげ図 | 分布の形 | カテゴリ別のばらつき比較 |
| クロス集計 | 比率表 | カテゴリ間の関係性 |
| 回帰分析 | 係数・p値 | 影響度と有意性の定量評価 |

散布図
![散布図](/images/scatter_plot.png)

ヒートマップ
![ヒートマップ](/images/correlation_heatmap.png)

箱ひげ図
![箱ひげ図](/images/box_plot.png)

個々の部分のヒントは統計学になります。ヒントをLLMに尋ねるのもいいと思います。

##### 数値が相応しい形式か
例えば与える数値が日付の場合、曜日に変換したらグラフでで傾向が見られた、という場合なら、曜日を項目として設けた方が良い結果に繋がる可能性があります。また、極端に大きい値や小さい値は正規化した方が良い場合があります。正規化にはいくつか方法がありますが、外れ値に注意した変換が必要です。
全てを数値化して演算するニューラルネットなどのモデルは正規化が効きます。

##### 多ければ良いと限らない不思議


##### カテゴリとワンホット（LGBMなど）
##### 偽相関に注意
#### 学習データの分割を考える
##### 行の範囲を考える
##### 交差検証を検討する
### モデルの検討
#### モデルは選べる
##### 得意分野を考える
##### 自動で選んでもらう
#### パラメータのチューニング
##### 自分で試す方法
##### 自動でチューニング
#### 複数モデルの活かし方

---

## 上位勢を参考にする
### 参加目的を考えて利用を推奨
### LLMに細かく解説させる
### 環境が違うと再現できないので注意